{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f7325f1",
   "metadata": {},
   "source": [
    "# Семинар 1: Generative Adversarial Networks\n",
    "\n",
    "## Вступление\n",
    "Одно из самых известных семейств архитектур, применяемых для генеративных задач в разных доменах, — это, конечно же, generative adversarial networks (GAN). GAN обычно состоит из двух сетей: генератора и дискриминатора. Дискриминатор пытается отличить сгенерированные объекты от реальных. Генератор пытается обмануть дискриминатор и сгенерировать такие объекты, которые он не сможет отличить от настоящих. Задача, которую решают сети, является минимаксной (одна сеть пытается минимизировать функционал, а другая максимизировать) и её точка равновесия достигается, когда генератор выдает объекты, полностью не отличимые от настоящих. Сегодня мы посмотрим примеры кода, реализующих GAN.\n",
    "\n",
    "### План семинара\n",
    "1. Реализуем GAN для двумерных данных\n",
    "2. Применяем GAN для MNIST\n",
    "3. Смотрим на сломанный GAN и пытаемся понять, почему так вышло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from typing_extensions import Literal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from IPython.display import clear_output\n",
    "from torch import nn, optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "device = \"cpu\"\n",
    "# torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb73a96",
   "metadata": {},
   "source": [
    "## 1. Vanilla GAN: двумерные данные\n",
    "\n",
    "Для Vanilla GAN функционал имеет следующий вид:\n",
    "\n",
    "$L(D, G) = - \\frac1n \\sum_{x_i \\in X} \\log D(x_i) - \\frac1n \\sum_{z_i \\in N(0, 1)} \\log (1 - D(G(z_i))) \\rightarrow \\min_{D} \\max_{G}$\n",
    "\n",
    "На практике, дискриминатор и генератор обучают не одновременно, а чередуют $n$ шагов оптимизации _только_ генератора и $m$ шагов оптимизации _только_ дискриминатора. В случае Vanilla GAN, эмпирически получается лучше, когда дискриминатор обучается больше шагов, чем генератор. $n$ и $m$ являются гиперпараметрами и подбираются под задачу архитектуры генератора и дискриминатора.\n",
    "\n",
    "Для подсчета лосса лучше не считать логарифм сигмоиды, а использовать функцию logsigmoid для подсчета обеих частей, работая напрямую с логитами дискриминатора. В случае $\\log (1 - D(G(z_i)))$ можно воспользоваться свойством $1 - \\sigma(x) = \\sigma(-x)$.\n",
    "\n",
    "Процесс обучения GAN'а выглядит так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a18c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_loss(real_objects_scores: torch.Tensor,\n",
    "             generated_objects_scores: torch.Tensor, \n",
    "             by: Literal[\"generator\", \"discriminator\"] = \"generator\") -> torch.Tensor:\n",
    "    if by==\"generator\":\n",
    "        return torch.log(1 - generated_objects_scores).mean()\n",
    "    elif by == \"discriminator\":\n",
    "        return -torch.log(real_objects_scores).mean() - torch.log(1 - generated_objects_scores).mean()\n",
    "\n",
    "    \n",
    "def train_gan(tr_dataloader,\n",
    "              gen, discr, \n",
    "              gen_opt, discr_opt,\n",
    "              loss_func, prior,\n",
    "              num_epochs, gen_steps, discr_steps,\n",
    "              discr_params_clip_value=None,\n",
    "              verbose_num_iters=100,\n",
    "              data_type=\"2d\"):\n",
    "    gen.train()\n",
    "    discr.train()\n",
    "    gen_loss_trace = []\n",
    "    discr_loss_trace = []\n",
    "\n",
    "    iter_i = 0\n",
    "\n",
    "    for epoch_i in range(num_epochs):        \n",
    "        print(f\"Epoch {epoch_i + 1}\")\n",
    "        for batch in tr_dataloader:\n",
    "            # берем реальные объекты\n",
    "            real_objects, y = batch\n",
    "            real_objects = real_objects.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # генерируем новые объекты\n",
    "            num_objects = real_objects.shape[0]\n",
    "            z = prior.sample((num_objects, ))\n",
    "            gen_objects = gen(z, y)\n",
    "\n",
    "            # считаем скоры\n",
    "            real_objects_scores, gen_objects_scores = torch.split(discr(\n",
    "                torch.cat([real_objects, gen_objects], dim=0), \n",
    "                torch.cat([y, y], dim=0)), num_objects)\n",
    "\n",
    "            if (iter_i % (gen_steps + discr_steps)) < gen_steps:\n",
    "                # делаем шаг обучения генератора\n",
    "                gen_opt.zero_grad()\n",
    "                gen_loss = loss_func(real_objects_scores, gen_objects_scores, \"generator\")\n",
    "                gen_loss.backward()\n",
    "                gen_opt.step()\n",
    "                gen_loss_trace.append((iter_i, gen_loss.item()))\n",
    "            else:\n",
    "                # делаем шаг обучения дискриминатора\n",
    "                discr_opt.zero_grad()\n",
    "                discr_loss = loss_func(real_objects_scores, gen_objects_scores, \"discriminator\")\n",
    "                discr_loss.backward()\n",
    "                discr_opt.step()\n",
    "                discr_loss_trace.append((iter_i, discr_loss.item()))\n",
    "        \n",
    "            iter_i += 1\n",
    "\n",
    "            # раз в verbose_num_iters визуализируем наши лоссы и семплы\n",
    "            if iter_i % verbose_num_iters == 0:\n",
    "                clear_output(wait=True)\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                \n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.xlabel(\"Iteration\")\n",
    "                plt.ylabel(\"Generator loss\")\n",
    "                plt.plot([p[0] for p in gen_loss_trace], \n",
    "                         [p[1] for p in gen_loss_trace])\n",
    "\n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.xlabel(\"Iteration\")\n",
    "                plt.ylabel(\"Discriminator loss\")\n",
    "                plt.plot([p[0] for p in discr_loss_trace], \n",
    "                         [p[1] for p in discr_loss_trace], color=\"orange\")\n",
    "                    \n",
    "                gen.eval()\n",
    "                if data_type == \"2d\":\n",
    "                    plt.subplot(1, 3, 3)\n",
    "                    with torch.no_grad():\n",
    "                        z = prior.sample((1024, ))\n",
    "                        sampled_2d = gen(z)\n",
    "                    x = real_objects.cpu().numpy()\n",
    "                    plt.xlim(x.min(0)[0], x.max(0)[0])\n",
    "                    plt.ylim(x.min(0)[1], x.max(0)[1])\n",
    "                    plt.scatter(\n",
    "                    sampled_2d[:, 0].cpu().detach().numpy(),\n",
    "                    sampled_2d[:, 1].cpu().detach().numpy(),\n",
    "                    s=1)\n",
    "                elif data_type == \"mnist\":\n",
    "                    with torch.no_grad():\n",
    "                        z = prior.sample((100, ))\n",
    "                        sampled_mnist = gen(z, torch.arange(100).to(device) % 10)\n",
    "\n",
    "                    for i in range(100):\n",
    "                        plt.subplot(10, 30, 30 * (i // 10) + 21 + (i % 10))\n",
    "                        plt.axis(\"off\")\n",
    "                        plt.imshow(sampled_mnist[i, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
    "\n",
    "                plt.show()\n",
    "                gen.train()\n",
    "                \n",
    "    gen.eval()\n",
    "    discr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb5c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "s_x, s_y = datasets.make_s_curve(n_samples=10000, noise=0.01)\n",
    "s_x = s_x[:, [0, 2]]\n",
    "plt.scatter(s_x[:, 0], s_x[:, 1], s=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66127a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset2d:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "\n",
    "class Generator2d(nn.Module):\n",
    "    def __init__(self, lat_size):\n",
    "        super(Generator2d, self).__init__()\n",
    "        self.lat_size = lat_size\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(lat_size, 32), \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, z: torch.Tensor, y: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        return self.net(z)\n",
    "\n",
    "\n",
    "class Discriminator2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator2d, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 32), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим сети, оптимизаторы, прайор и даталоадер\n",
    "\n",
    "tr_dataloader_2d = torch.utils.data.DataLoader(\n",
    "    Dataset2d(torch.tensor(s_x, dtype=torch.float32), \n",
    "              torch.tensor(s_y)),\n",
    "              batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "gen_2d = Generator2d(2)\n",
    "gen_2d.to(device)\n",
    "\n",
    "discr_2d = Discriminator2d()\n",
    "discr_2d.to(device)\n",
    "\n",
    "prior_2d = torch.distributions.Normal(torch.zeros(2).to(device), torch.ones(2).to(device))\n",
    "\n",
    "gen_opt_2d = optim.Adam(gen_2d.parameters(), lr=3e-4)\n",
    "discr_opt_2d = optim.Adam(discr_2d.parameters(), lr=3e-4, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db4bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(tr_dataloader_2d, gen_2d, discr_2d, gen_opt_2d, discr_opt_2d, gan_loss, prior_2d,\n",
    "          num_epochs=30, gen_steps=1, discr_steps=3,\n",
    "          verbose_num_iters=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298d875",
   "metadata": {},
   "source": [
    "Визуализируем распределение, которое выучил генератор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2946b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = prior_2d.sample((256, ))\n",
    "\n",
    "sampled_2d = gen_2d(z)\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-2, 2)\n",
    "\n",
    "plt.scatter(sampled_2d[:, 0].cpu().detach().numpy(),\n",
    "            sampled_2d[:, 1].cpu().detach().numpy(),\n",
    "            s=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a3b88",
   "metadata": {},
   "source": [
    "2d данные отлично подходят и для демонстрации слабых мест GAN'ов: когда данные состоят из нескольких мод (кластеров), ганы подверждены двум сценариям.\n",
    "\n",
    "1. Mode collapse: ситуация, когда GAN игнорирует часть кластеров и не пытается их выучить.\n",
    "2. Смешение мод: когда GAN соединяется две моды перешейком. Этот случай, как правило, решается взятием более мощного дискриминатора и генератора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cac2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "circle_x, circle_y = datasets.make_circles(n_samples=10000, noise=0.01)\n",
    "plt.scatter(circle_x[:, 0], circle_x[:, 1], s=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3800a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataloader_circle = torch.utils.data.DataLoader(\n",
    "    Dataset2d(torch.tensor(circle_x, dtype=torch.float32), \n",
    "              torch.tensor(circle_y)),\n",
    "              batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "gen_circle = Generator2d(2)\n",
    "gen_circle.to(device)\n",
    "\n",
    "discr_circle = Discriminator2d()\n",
    "discr_circle.to(device)\n",
    "\n",
    "prior_circle = torch.distributions.Normal(torch.zeros(2).to(device), torch.ones(2).to(device))\n",
    "\n",
    "gen_opt_circle = optim.Adam(gen_circle.parameters(), lr=3e-4)\n",
    "discr_opt_circle = optim.Adam(discr_circle.parameters(), lr=3e-4, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5dda7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(tr_dataloader_circle, gen_circle, \n",
    "          discr_circle, gen_opt_circle, discr_opt_circle, \n",
    "          gan_loss, prior_circle,\n",
    "          num_epochs=30, gen_steps=1, discr_steps=3,\n",
    "          verbose_num_iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d7e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = prior_circle.sample((1024, ))\n",
    "\n",
    "sampled_circle = gen_circle(z)\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.scatter(sampled_circle[:, 0].cpu().detach().numpy(),\n",
    "            sampled_circle[:, 1].cpu().detach().numpy(),\n",
    "            s=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f8b1f",
   "metadata": {},
   "source": [
    "## 2. Vanilla GAN: MNIST\n",
    "\n",
    "Теперь давайте обучим ту же самую архитектуру на чуть-чуть более серьёзные данных. Попробуем генерировать цифры из датасета MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorMNIST(nn.Module):\n",
    "    def __init__(self, lat_size, hidden=64):\n",
    "        super().__init__()\n",
    "        self.lat_size = lat_size\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(lat_size, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, 2 * hidden),\n",
    "            nn.BatchNorm1d(2 * hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * hidden, 4 * hidden),\n",
    "            nn.BatchNorm1d(4 * hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * hidden, 32 * 32),\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, z: torch.Tensor, y: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        return self.net(z).view(-1, 1, 32, 32)\n",
    "\n",
    "class DiscriminatorMNIST(nn.Module):\n",
    "    def __init__(self, hidden=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(32 * 32, 4 * hidden), \n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(4 * hidden, 2 * hidden),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(2 * hidden, hidden),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden, 1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        res = self.net(x.view(-1, 32 * 32))\n",
    "        res = torch.sigmoid(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd255a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(32),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = MNIST(root=\"./data/\", train=True, download=True, transform=transform)\n",
    "trainloader_mnist = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc97df",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_mnist = GeneratorMNIST(100)\n",
    "gen_mnist.to(device)\n",
    "\n",
    "discr_mnist = DiscriminatorMNIST()\n",
    "discr_mnist.to(device)\n",
    "\n",
    "prior_mnist = torch.distributions.Normal(torch.zeros(100).to(device), torch.ones(100).to(device))\n",
    "\n",
    "gen_opt_mnist = optim.Adam(gen_mnist.parameters(), lr=3e-4)\n",
    "discr_opt_mnist = optim.Adam(discr_mnist.parameters(), lr=3e-4, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34dd337",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(trainloader_mnist, gen_mnist, \n",
    "          discr_mnist, gen_opt_mnist, discr_opt_mnist, \n",
    "          gan_loss, prior_mnist,\n",
    "          num_epochs=20, gen_steps=1, discr_steps=1,\n",
    "          verbose_num_iters=100, data_type=\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a80109",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = prior_mnist.sample((16, ))\n",
    "\n",
    "sampled_mnist = gen_mnist(z)\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(sampled_mnist[i, 0].detach().cpu().numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d24e510",
   "metadata": {},
   "source": [
    "Получается, в общем-то, более менее недурно!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84603586",
   "metadata": {},
   "source": [
    "## 3. Vanilla GAN: Fashion MNIST\n",
    "\n",
    "### 3.1 Имплементируем работающее решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82d3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDiscriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_dim * 4)\n",
    "        self.fc2 = nn.Linear(hidden_dim * 4, hidden_dim * 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim,output_size)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.leaky_relu(self.fc1(x),0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x),0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc3(x),0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "class SimpleGenerator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size,hidden_dim*2)\n",
    "        self.fc2 = nn.Linear(hidden_dim*2,hidden_dim*4)\n",
    "        self.fc3 = nn.Linear(hidden_dim*4,output_size)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x),0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x),0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = (self.fc3(x))\n",
    "        x = torch.tanh(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d8f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator hyperparams\n",
    "\n",
    "# Size of input image to discriminator (28*28)\n",
    "input_size = 28 * 28\n",
    "# Size of discriminator output (real or fake)\n",
    "d_output_size = 1\n",
    "# Size of *last* hidden layer in the discriminator\n",
    "d_hidden_size = 32\n",
    "\n",
    "# Generator hyperparams\n",
    "\n",
    "# Size of latent vector to give to generator\n",
    "z_size = 100\n",
    "# Size of discriminator output (generated image)\n",
    "g_output_size = 28 * 28\n",
    "# Size of *first* hidden layer in the generator\n",
    "g_hidden_size = 32\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57546e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate discriminator and generator\n",
    "D = SimpleDiscriminator(input_size, d_hidden_size, d_output_size)\n",
    "G = SimpleGenerator(z_size, g_hidden_size, g_output_size)\n",
    "\n",
    "# check that they are as you expect\n",
    "print(D)\n",
    "print()\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e476d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate losses\n",
    "def real_loss(D_out, smooth=False):\n",
    "    # compare logits to real labels\n",
    "    # smooth labels if smooth=True\n",
    "    batch_size = D_out.size(0)\n",
    "    if smooth:\n",
    "        labels = torch.ones(batch_size) * 0.9\n",
    "    else:\n",
    "        labels = torch.ones(batch_size)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    loss = criterion(D_out.squeeze(), labels)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def fake_loss(D_out):\n",
    "    # compare logits to fake labels\n",
    "    batch_size = D_out.size(0)\n",
    "    labels = torch.zeros(batch_size)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    loss = criterion(D_out.squeeze(),labels)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5d0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.002\n",
    "\n",
    "d_optimizer = optim.Adam(D.parameters(), lr)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb75d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "training_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b42de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13bdbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(training_data[0][0])\n",
    "print(training_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e27381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    training_data, \n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8bfe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = SimpleDiscriminator(input_size, d_hidden_size, d_output_size)\n",
    "G = SimpleGenerator(z_size, g_hidden_size, g_output_size)\n",
    "d_optimizer = optim.Adam(D.parameters(), lr)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc862c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "\n",
    "samples = []\n",
    "losses = []\n",
    "\n",
    "print_every = 400\n",
    "\n",
    "# Get some fixed data for sampling. These are images that are held\n",
    "# constant throughout training, and allow us to inspect the model's performance\n",
    "sample_size = 16\n",
    "fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
    "fixed_z = torch.from_numpy(fixed_z).float()\n",
    "\n",
    "# train the network\n",
    "D.train()\n",
    "G.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_i, (real_images, _) in enumerate(train_loader):\n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        ## Important rescaling step ## \n",
    "        real_images = real_images * 2 - 1  # rescale input images from [0,1) to [-1, 1)\n",
    "        \n",
    "        # ============================================\n",
    "        #            TRAIN THE DISCRIMINATOR\n",
    "        # ============================================\n",
    "                \n",
    "        # 1. Train with real images\n",
    "        d_optimizer.zero_grad()\n",
    "\n",
    "        # Compute the discriminator losses on real images\n",
    "        # use smoothed labels\n",
    "        op_real = D(real_images)\n",
    "        d_real_loss = real_loss(op_real,smooth = True)\n",
    "        \n",
    "        \n",
    "        # 2. Train with fake images\n",
    "        \n",
    "        # Generate fake images\n",
    "        z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
    "        z = torch.from_numpy(z).float()\n",
    "        fake_images = G(z)\n",
    "        \n",
    "        # Compute the discriminator losses on fake images \n",
    "        op_fake = D(fake_images)\n",
    "        #print(type(fake_loss))\n",
    "        d_fake_loss = fake_loss(op_fake)\n",
    "        \n",
    "        # add up real and fake losses and perform backprop\n",
    "        d_loss = d_fake_loss + d_real_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # =========================================\n",
    "        #            TRAIN THE GENERATOR\n",
    "        # =========================================\n",
    "        \n",
    "        # 1. Train with fake images and flipped labels\n",
    "        g_optimizer.zero_grad()\n",
    "        \n",
    "        # Generate fake images\n",
    "        z = np.random.uniform(-1,1,size = (batch_size,z_size))\n",
    "        z = torch.from_numpy(z).float()\n",
    "        fake_images = G(z)\n",
    "        \n",
    "        # Compute the discriminator losses on fake images \n",
    "        # using flipped labels!\n",
    "        d_fake_loss = D(fake_images)\n",
    "        g_loss = real_loss(d_fake_loss)\n",
    "\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "\n",
    "        # Print some loss stats\n",
    "        if batch_i % print_every == 0:\n",
    "            # print discriminator and generator loss\n",
    "            print(\"Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}\".format(\n",
    "                    epoch+1, num_epochs, d_loss.item(), g_loss.item()))\n",
    "\n",
    "    \n",
    "    ## AFTER EACH EPOCH##\n",
    "    # append discriminator loss and generator loss\n",
    "    losses.append((d_loss.item(), g_loss.item()))\n",
    "    \n",
    "    # generate and save sample, fake images\n",
    "    G.eval() # eval mode for generating samples\n",
    "    samples_z = G(fixed_z)\n",
    "    samples.append(samples_z)\n",
    "    G.train() # back to train mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a8630",
   "metadata": {},
   "source": [
    "## 3.2 Изучаем неработающее решение\n",
    "\n",
    "Давайте теперь попробуем более сложную модель, которую использовали на картинках 64х64 и интерьерами квартир в этой [статье](https://arxiv.org/abs/1511.06434). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19fd94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGenerator(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( input_size, 32, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d( 16, 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d( 8, 4, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d( 4, 1, 2, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], x.shape[1], 1, 1)\n",
    "        x = self.seq(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class ConvDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, 4, 2, 1, bias=False), \n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(4, 8, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(8, 16, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(16, 1, 4, 2, 1, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26711f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = ConvDiscriminator()\n",
    "G = ConvGenerator(100)\n",
    "d_optimizer = optim.Adam(D.parameters(),lr)\n",
    "g_optimizer = optim.Adam(G.parameters(),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21135240",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "samples = []\n",
    "losses = []\n",
    "\n",
    "print_every = 400\n",
    "\n",
    "# Get some fixed data for sampling. These are images that are held\n",
    "# constant throughout training, and allow us to inspect the model's performance\n",
    "sample_size = 16\n",
    "fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
    "fixed_z = torch.from_numpy(fixed_z).float()\n",
    "\n",
    "# train the network\n",
    "D.train()\n",
    "G.train()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch_i, (real_images, _) in enumerate(train_loader):\n",
    "                \n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        ## Important rescaling step ## \n",
    "        real_images = real_images * 2 - 1  # rescale input images from [0,1) to [-1, 1)\n",
    "        \n",
    "        # ============================================\n",
    "        #            TRAIN THE DISCRIMINATOR\n",
    "        # ============================================\n",
    "                \n",
    "        # 1. Train with real images\n",
    "        d_optimizer.zero_grad()\n",
    "\n",
    "        # Compute the discriminator losses on real images\n",
    "        # use smoothed labels\n",
    "        op_real = D(real_images)\n",
    "        d_real_loss = real_loss(op_real,smooth = True)\n",
    "        \n",
    "        \n",
    "        # 2. Train with fake images\n",
    "        \n",
    "        # Generate fake images\n",
    "        z = torch.randn(batch_size, z_size)\n",
    "        fake_images = G(z)\n",
    "        \n",
    "        # Compute the discriminator losses on fake images \n",
    "        op_fake = D(fake_images)\n",
    "        #print(type(fake_loss))\n",
    "        d_fake_loss = fake_loss(op_fake)\n",
    "        \n",
    "        # add up real and fake losses and perform backprop\n",
    "        d_loss = d_fake_loss + d_real_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # =========================================\n",
    "        #            TRAIN THE GENERATOR\n",
    "        # =========================================\n",
    "        \n",
    "        # 1. Train with fake images and flipped labels\n",
    "        g_optimizer.zero_grad()\n",
    "        \n",
    "        # Generate fake images\n",
    "        z = np.random.uniform(-1, 1,size = (batch_size,z_size))\n",
    "        z = torch.from_numpy(z).float()\n",
    "        fake_images = G(z)\n",
    "        \n",
    "        # Compute the discriminator losses on fake images \n",
    "        # using flipped labels!\n",
    "        d_fake_loss = D(fake_images)\n",
    "        g_loss = real_loss(d_fake_loss)\n",
    "\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "\n",
    "        # Print some loss stats\n",
    "        if batch_i % print_every == 0:\n",
    "            # print discriminator and generator loss\n",
    "            print(\"Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}\".format(\n",
    "                    epoch+1, num_epochs, d_loss.item(), g_loss.item()))\n",
    "\n",
    "    \n",
    "    ## AFTER EACH EPOCH##\n",
    "    # append discriminator loss and generator loss\n",
    "    losses.append((d_loss.item(), g_loss.item()))\n",
    "    \n",
    "    # generate and save sample, fake images\n",
    "    G.eval() # eval mode for generating samples\n",
    "    samples_z = G(fixed_z)\n",
    "    samples.append(samples_z)\n",
    "    G.train() # back to train mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe8ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = []\n",
    "\n",
    "for l in tqdm(range(0, len(samples))):\n",
    "    step = 0\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            axes[i, j].imshow(samples[l][step].reshape(28, 28).detach().numpy(), cmap=\"Greys_r\")\n",
    "            step += 1\n",
    "    figs.append(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ce01c6",
   "metadata": {},
   "source": [
    "В этом случае у нас ничего не выходит, потому что данные очень простые, а дискриминатор довольно сильный. В итоге дискриминатор быстро учится различать настоящие данные и фейки, а генератор не учится."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
